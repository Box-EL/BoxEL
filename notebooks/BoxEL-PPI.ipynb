{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import wandb\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "\n",
    "torch.cuda.set_device(1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--no_cuda', action='store_true', default=False, help='disables CUDA training (eg. no nvidia GPU)')\n",
    "parser.add_argument('--epochs', type=int, default=1000, help='number of epochs to train')\n",
    "# model parameters\n",
    "parser.add_argument('--model', type=str, default='softbox', help='model type: choose from softbox, gumbel')\n",
    "parser.add_argument('--box_embedding_dim', type=int, default=40, help='box embedding dimension')\n",
    "parser.add_argument('--softplus_temp', type=float, default=1.0, help='beta of softplus function')\n",
    "# gumbel box parameters\n",
    "parser.add_argument('--gumbel_beta', type=float, default=1.0, help='beta value for gumbel distribution')\n",
    "parser.add_argument('--scale', type=float, default=1.0, help='scale value for gumbel distribution')\n",
    "\n",
    "parser.add_argument('--dataset', type=str, default='PPI', help='dataset')\n",
    "parser.add_argument('--using_rbox', type=int, default=1, help='using_rbox')\n",
    "parser.add_argument('--gpu', type=int, default=1, help='gpu')\n",
    "\n",
    "parser.add_argument('--dimension', type=int, default=50, help='dimension')\n",
    "parser.add_argument('--learning_rate', type=int, default=0.001, help='learning_rate')\n",
    "parser.add_argument('--batch_size', type=int, default=256, help='batch_size')\n",
    "parser.add_argument('--seed', type=int, default=1111, help='seed')\n",
    "\n",
    "args = parser.parse_args(args=['--no_cuda'] )\n",
    "args.save_to = \"./checkpoints/\" + args.model\n",
    "\n",
    "gpu = args.gpu\n",
    "dimension = args.dimension\n",
    "learning_rate = args.learning_rate\n",
    "batch_size = args.batch_size\n",
    "seed = args.seed\n",
    "dataset = args.dataset\n",
    "using_rbox = args.using_rbox\n",
    "\n",
    "torch.cuda.set_device(2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(seed)\n",
    "import random\n",
    "random.seed(seed)\n",
    "\n",
    "import torch\n",
    "from ppi_data_loader import load_cls,load_valid_data\n",
    "from ppi_data_loader import load_data\n",
    "from ppi_data_loader import Generator\n",
    "from evaluation import compute_mean_rank,compute_rank,compute_accuracy\n",
    "from box_model import BoxELPPI as Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data samples: 171740\n",
      "Training data classes: 5502\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = 'PPI'\n",
    "\n",
    "total_sub_cls = []\n",
    "train_file = f\"data/{dataset}/{dataset}_train.txt\"\n",
    "va_file = f\"data/{dataset}/{dataset}_valid.txt\"\n",
    "test_file = f\"data/{dataset}/{dataset}_test.txt\"\n",
    "train_sub_cls, train_samples = load_cls(train_file)\n",
    "valid_sub_cls, valid_samples = load_cls(va_file)\n",
    "test_sub_cls,test_samples = load_cls(test_file)\n",
    "total_sub_cls = train_sub_cls + valid_sub_cls + test_sub_cls\n",
    "all_subcls = list(set(total_sub_cls))\n",
    "\n",
    "print(\"Training data samples:\",train_samples)\n",
    "print(\"Training data classes:\",len(train_sub_cls))\n",
    "\n",
    "gdata_file=f\"data/{dataset}/{dataset}_latest_norm_mod.owl\"\n",
    "train_data, classes, relations = load_data(gdata_file)\n",
    "valid_data_file=f\"data/{dataset}/{dataset}_valid.txt\"\n",
    "valid_data = load_valid_data(valid_data_file, classes, relations)\n",
    "valid_data = torch.Tensor(valid_data).long().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nf1': array([[ 6410,    -1, 35259],\n",
       "        [42837,    -1, 18989],\n",
       "        [  707,    -1,    32],\n",
       "        ...,\n",
       "        [40420,    -1, 38998],\n",
       "        [35844,    -1,    32],\n",
       "        [43256,    -1, 14563]]), 'nf2': array([[   32, 26966,  3507],\n",
       "        [   32, 29579,  2607],\n",
       "        [   32, 45921, 10815],\n",
       "        ...,\n",
       "        [46530,    32, 21459],\n",
       "        [   32, 45472,  5301],\n",
       "        [40939, 44451, 41792]]), 'nf3': array([[20136,     0, 33676],\n",
       "        [43756,     6,  2971],\n",
       "        [ 8610,     3, 46676],\n",
       "        ...,\n",
       "        [14405,     5, 29897],\n",
       "        [25936,     5, 31069],\n",
       "        [ 6191,     3, 38848]]), 'nf4': array([[    6, 29313,  7624],\n",
       "        [    3, 19797,  3072],\n",
       "        [    0, 15187, 31853],\n",
       "        ...,\n",
       "        [    3, 47475, 31855],\n",
       "        [    5,  9012, 21716],\n",
       "        [    5,  1564, 20949]]), 'disjoint': array([[33686, 12492, 12493],\n",
       "        [26018, 11978, 12493],\n",
       "        [12492, 48917, 12493],\n",
       "        [25016, 12492, 12493],\n",
       "        [15106, 16938, 12493],\n",
       "        [ 1031, 12492, 12493],\n",
       "        [32367, 29948, 12493],\n",
       "        [ 7483,  6477, 12493],\n",
       "        [12492, 10241, 12493],\n",
       "        [27505, 12492, 12493],\n",
       "        [12492, 47060, 12493],\n",
       "        [ 3619, 12492, 12493],\n",
       "        [19960, 20454, 12493],\n",
       "        [ 4874, 12492, 12493],\n",
       "        [12492,   559, 12493],\n",
       "        [ 4966, 12492, 12493],\n",
       "        [14615, 14850, 12493],\n",
       "        [ 5778, 12492, 12493],\n",
       "        [39282, 12492, 12493],\n",
       "        [43517, 43518, 12493],\n",
       "        [  874, 12492, 12493],\n",
       "        [45072, 34337, 12493],\n",
       "        [12492, 31212, 12493],\n",
       "        [12724, 10912, 12493],\n",
       "        [ 2934, 12492, 12493],\n",
       "        [ 8219, 12492, 12493],\n",
       "        [12492, 31564, 12493],\n",
       "        [19960, 23631, 12493],\n",
       "        [27892,  5778, 12493],\n",
       "        [12492, 32997, 12493]]), 'nf_inclusion': array([[0, 3],\n",
       "        [8, 9],\n",
       "        [5, 3]]), 'nf_chain': array([[3, 3, 3],\n",
       "        [3, 6, 3],\n",
       "        [7, 6, 7],\n",
       "        [0, 6, 0],\n",
       "        [5, 6, 5],\n",
       "        [6, 7, 7],\n",
       "        [6, 6, 6],\n",
       "        [0, 0, 5],\n",
       "        [4, 4, 4],\n",
       "        [8, 8, 8]]), 'interact': array([[ 4393,     1,  4392],\n",
       "        [ 9940,     1,  9958],\n",
       "        [ 1625,     1,  3259],\n",
       "        ...,\n",
       "        [ 5343,     1,  3028],\n",
       "        [ 1452,     1,   741],\n",
       "        [ 5720,     1, 14162]]), 'hasFunction': array([[  577,     2,  9425],\n",
       "        [13839,     2,  8690],\n",
       "        [ 2570,     2,   145],\n",
       "        ...,\n",
       "        [ 5549,     2, 34200],\n",
       "        [ 1053,     2, 21213],\n",
       "        [ 7091,     2,  1301]]), 'interact_neg': array([[ 1959,     1, 10329],\n",
       "        [ 2526,     1,  3054],\n",
       "        [22670,     1,  8254],\n",
       "        ...,\n",
       "        [ 6673,     1,  4813],\n",
       "        [16758,     1,  6719],\n",
       "        [ 4121,     1,  5850]]), 'top': array([51688])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proteins: 5502\n",
      "no. classes: 51689\n",
      "no. relations: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    2],\n",
       "        [    3],\n",
       "        [    4],\n",
       "        ...,\n",
       "        [51236],\n",
       "        [51496],\n",
       "        [51497]], device='cuda:2')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256 \n",
    "\n",
    "org = 4932\n",
    "proteins = {}\n",
    "for k, v in classes.items():\n",
    "    if k.startswith(f'<http://{org}'):\n",
    "        proteins[k] = v\n",
    "print('Proteins:', len(proteins))\n",
    "\n",
    "nb_classes = len(classes)\n",
    "nb_relations = len(relations)\n",
    "\n",
    "print(\"no. classes:\",nb_classes)\n",
    "print(\"no. relations:\",nb_relations)\n",
    "nb_train_data = 0\n",
    "\n",
    "for key, val in train_data.items():\n",
    "    nb_train_data = max(len(val), nb_train_data)\n",
    "    \n",
    "train_steps = int(math.ceil(nb_train_data / (1.0 * batch_size)))\n",
    "train_generator = Generator(train_data, batch_size, steps=train_steps)\n",
    "\n",
    "cls_dict = {v: k for k, v in classes.items()}\n",
    "rel_dict = {v: k for k, v in relations.items()}\n",
    "\n",
    "cls_list = []\n",
    "rel_list = []\n",
    "for i in range(nb_classes):\n",
    "    cls_list.append(cls_dict[i])\n",
    "for i in range(nb_relations):\n",
    "    rel_list.append(rel_dict[i])\n",
    "\n",
    "classes_index = list(classes.values())\n",
    "classes_index = torch.Tensor(classes_index).to(device).reshape(-1,1).long()\n",
    "classes_index.shape\n",
    "\n",
    "protein_index = list(proteins.values())\n",
    "protein_index = torch.Tensor(protein_index).to(device).reshape(-1,1).long()\n",
    "protein_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>Run(1bl2oncu)</h1><iframe src=\"https://wandb.ai/boxiong/basic_box/runs/1bl2oncu\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ff1046a83c8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"basic_box\", reinit=False, config=args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = Model(nb_classes, nb_relations, 50, [1e-4, 0.2], [-0.1, 0], [-0.1,0.1], [0.9,1.1], args).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "wandb.watch(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 Train loss: 3.478361 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:11 Train loss: 3.474711 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:21 Train loss: 3.479704 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:31 Train loss: 3.482792 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:41 Train loss: 3.479377 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:51 Train loss: 3.494027 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:61 Train loss: 3.480729 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:71 Train loss: 3.487980 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:81 Train loss: 3.491811 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:91 Train loss: 3.486822 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:101 Train loss: 3.475150 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:111 Train loss: 3.494037 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:121 Train loss: 3.490071 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:131 Train loss: 3.488562 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:141 Train loss: 3.481843 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:151 Train loss: 3.500453 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:161 Train loss: 3.469411 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:171 Train loss: 3.484949 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:181 Train loss: 3.485209 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:191 Train loss: 3.479152 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:201 Train loss: 3.471668 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:211 Train loss: 3.478905 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:221 Train loss: 3.486227 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:231 Train loss: 3.480253 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:241 Train loss: 3.483212 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:251 Train loss: 3.480737 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:261 Train loss: 3.495636 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:271 Train loss: 3.474825 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:281 Train loss: 3.497506 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:291 Train loss: 3.476150 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:301 Train loss: 3.480565 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:311 Train loss: 3.496240 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:321 Train loss: 3.488354 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:331 Train loss: 3.492391 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:341 Train loss: 3.485493 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:351 Train loss: 3.509048 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:361 Train loss: 3.479954 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:371 Train loss: 3.480157 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:381 Train loss: 3.499581 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:391 Train loss: 3.487615 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:401 Train loss: 3.469106 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:411 Train loss: 3.484781 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:421 Train loss: 3.473982 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:431 Train loss: 3.480579 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:441 Train loss: 3.503201 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:451 Train loss: 3.490118 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:461 Train loss: 3.477801 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:471 Train loss: 3.501244 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:481 Train loss: 3.483634 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:491 Train loss: 3.498587 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:501 Train loss: 3.490521 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:511 Train loss: 3.492485 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:521 Train loss: 3.496206 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:531 Train loss: 3.491491 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:541 Train loss: 3.500094 Valid Mean Rank: 0\n",
      "\n",
      "Epoch:551 Train loss: 3.482695 Valid Mean Rank: 0\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-68e51410f016>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/anaconda3/envs/box/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/anaconda3/envs/box/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.train()\n",
    "steps_per_epoch = train_steps\n",
    "train_generator.reset()\n",
    "\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    nf1_total_loss = 0.0\n",
    "    nf2_total_loss = 0.0\n",
    "    nf3_total_loss = 0.0\n",
    "    nf4_total_loss = 0.0\n",
    "    disjoint_total_loss = 0.0\n",
    "    nf3_neg_total_loss = 0.0\n",
    "    ri_total_loss = 0.0\n",
    "    rc_total_loss = 0.0\n",
    "    int_total_loss = 0.0\n",
    "    mem_total_loss = 0.0\n",
    "    \n",
    "    for step, batch in enumerate(train_generator):\n",
    "        if step < steps_per_epoch:\n",
    "            n1,n2,n3,n4,dis,n3n,ri,rc,inter,member,reg1,reg2,reg3,reg4,reg_dis,reg3_n,reg_inter, reg_member = model(batch[0])\n",
    "            loss = n1+n2+n3+n4+dis+n3n+ri+rc+inter+member+reg1+reg2+reg3+reg4+reg_dis+reg3_n+reg_inter+reg_member\n",
    "            \n",
    "            assert torch.isnan(loss).sum() == 0\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            assert torch.isnan(model.min_embedding).sum() == 0\n",
    "            optimizer.step()\n",
    "            assert torch.isnan(model.min_embedding).sum() == 0\n",
    "            assert torch.isnan(model.min_embedding.grad).sum() == 0\n",
    "            train_loss += loss\n",
    "            nf1_total_loss += n1\n",
    "            nf2_total_loss += n2\n",
    "            nf3_total_loss += n3\n",
    "            nf4_total_loss += n4\n",
    "            disjoint_total_loss += dis\n",
    "            nf3_neg_total_loss += n3n\n",
    "            ri_total_loss +=ri\n",
    "            rc_total_loss += rc\n",
    "            int_total_loss += inter\n",
    "            mem_total_loss = member\n",
    "        else:\n",
    "            train_generator.reset()\n",
    "            break\n",
    "            \n",
    "    mean_rank = 0\n",
    "    valid_accuracy = compute_accuracy(model, valid_data)\n",
    "    \n",
    "#     wandb.log({'train loss': train_loss.item()/(step+1),'nf1_loss':nf1_total_loss.item()/(step+1), 'nf2_loss':nf2_total_loss.item()/(step+1), 'nf3_loss':nf3_total_loss.item()/(step+1), 'nf4_loss':nf4_total_loss.item()/(step+1), 'nf3_neg_loss':nf3_neg_total_loss.item()/(step+1), \n",
    "#                 'role_inclusion_loss': ri_total_loss.item()/(step+1),'role_chain_loss': rc_total_loss.item()/(step+1), 'interaction_loss': int_total_loss.item()/(step+1),'function_loss': mem_total_loss.item()/(step+1), 'mean_rank':mean_rank,'valid_accuracy':valid_accuracy })\n",
    "\n",
    "    PATH = './models/box_el_ppi.pt'\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(model, PATH)\n",
    "        print('Epoch:%d' %(epoch + 1), \"Train loss: %f\" %(train_loss.item()/(step+1)), f'Valid Mean Rank: {mean_rank}\\n')\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PATH = './models/box_el_ppi.pt'\n",
    "# PATH = './models/box_el_ppi_boxes.pt'\n",
    "model = torch.load(PATH)\n",
    "\n",
    "test_file = f'data/{dataset}/{dataset}_test.txt'\n",
    "test_data = load_valid_data(test_file,classes,relations)\n",
    "test_data = torch.Tensor(test_data).long().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.00586756077116513 0.06198193163826022 1718.2797569153395 1329.0 4000.0 0.9665397516576638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "top1,top10, top100, mean_rank, median_rank, per_rank, auc,rank_values = compute_rank(model, test_data, 90, proteins, device)\n",
    "print(top1,top10, top100, mean_rank, median_rank, per_rank, auc)\n",
    "\n",
    "compute_accuracy(model, test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0005122473689112415 0.009173884697774052 2831.051154884977 2277.0 5164.700000000001 0.9451738970891046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1102728881438018"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "top1,top10, top100, mean_rank, median_rank, per_rank, auc,rank_values = compute_rank(model, test_data, 90,classes,device)\n",
    "print(top1,top10, top100, mean_rank, median_rank, per_rank, auc)\n",
    "\n",
    "compute_accuracy(model, test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0005122473689112415 0.009173884697774052 2831.051154884977 2277.0 5164.700000000001 0.9451738970891046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1102728881438018"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "top1,top10, top100, mean_rank, median_rank, per_rank, auc,rank_values = compute_rank(model, test_data, 90,classes,device)\n",
    "print(top1,top10, top100, mean_rank, median_rank, per_rank, auc)\n",
    "\n",
    "compute_accuracy(model, test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-35-281f82d2bf01>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-35-281f82d2bf01>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    testing: 1111 0.0 0.00430416068866571 0.11477761836441894 3118.3922166427546 921.0 10303.800000000001 0.8714267973960943 0.6603299856527977\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "testing: 1111 0.0 0.00430416068866571 0.11477761836441894 3118.3922166427546 921.0 10303.800000000001 0.8714267973960943 0.6603299856527977\n",
    "inference: 1111 0.0 0.010766194150367845 0.2015072671810515 1067.8097075183923 415.5 2987.4 0.9551401890471426 0.9944374663556432\n",
    "testing: 2222 0.0 0.005380200860832138 0.10616929698708752 3174.333213773314 919.0 10598.800000000007 0.8691295137086096 0.6535150645624104\n",
    "inference: 2222 0.0 0.01040732101202225 0.2013278306118787 1080.09976673246 413.5 3016.6000000000004 0.9553046959013611 0.9942580297864705\n",
    "testing: 3333 0.0 0.006097560975609756 0.1133428981348637 3161.330164992826 935.25 10594.400000000001 0.8700184004504289 0.6574605451936872\n",
    "inference: 3333 0.0 0.013637179257132604 0.20455768885698905 1084.1268616544053 424.5 2986.5 0.9548764847827171 0.9938991566481249\n",
    "testing: 4444 0.0 0.007173601147776184 0.11406025824964132 3117.961262553802 894.25 10008.6 0.8717968588033929 0.6660688665710186\n",
    "inference: 4444 0.0 0.013278306118787008 0.20240445002691548 1077.5013457742689 404.5 3060.2000000000003 0.9555499005819137 0.9949757760631617\n",
    "testing: 5555 0.0 0.004662840746054519 0.1093974175035868 3128.779949784792 898.0 10143.950000000006 0.8713564583707556 0.6477761836441894\n",
    "inference: 5555 0.0 0.011304503857886236 0.19845684550511394 1065.7015072671811 411.5 2936.4 0.9558965683789529 0.9930019738022609\n",
    "\n",
    "testing: 6666 0.0 0.005021520803443328 0.10616929698708752 3153.3669296987086 905.75 10360.600000000002 0.8703439527157969 0.6581779053084649\n",
    "inference: 6666 0.0 0.01040732101202225 0.19773909922842275 1093.2905078054907 423.5 3051.8 0.9547617037341984 0.9938991566481249\n",
    "    \n",
    "testing: 7777 0.0 0.006097560975609756 0.11011477761836441 3099.3681850789094 920.75 9882.500000000011 0.8714952769643954 0.6588952654232425\n",
    "inference: 7777 0.0 0.012739996411268616 0.19630360667504038 1081.3397631437288 427.0 3037.2000000000003 0.9552559924265435 0.9947963394939888\n",
    "    \n",
    "testing: 8888 0.0 0.006097560975609756 0.10975609756097561 3091.743364418938 910.75 9711.90000000002 0.872874780525156 0.6588952654232425\n",
    "inference: 8888 0.0 0.01184281356540463 0.1941503678449668 1080.7852144267001 418.5 3030.8000000000006 0.9550102572391543 0.9942580297864705\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "1111 0.0 0.005738880918220947 0.10294117647058823 2876.125717360115 972.0 8990.45000000001 0.8751919911650198 0.6578192252510761\n",
    "1111 0.0 0.016328727794724565 0.1955858603983492 1030.250134577427 428.0 2725.600000000001 0.9554435551497155 0.9953346492015073\n",
    "\n",
    "2222 0.0 0.007173601147776184 0.0979196556671449 2907.119081779053 972.75 9664.400000000001 0.8742102474870697 0.6653515064562411\n",
    "2222 0.0 0.014713798672169388 0.19630360667504038 1031.4783778934147 430.5 2654.8 0.9553963485689416 0.9944374663556432\n",
    "\n",
    "3333 0.0 0.005021520803443328 0.11011477761836441 2939.3970588235293 972.75 9499.400000000005 0.872463057751984 0.6700143472022956\n",
    "3333 0.0 0.012739996411268616 0.19343262156827562 1017.0012560559842 422.5 2652.6000000000004 0.9560219302626464 0.9951552126323344\n",
    "\n",
    "4444 0.0 0.007890961262553802 0.11047345767575323 2962.374820659971 964.25 9546.800000000001 0.8714725880835268 0.6631994261119082\n",
    "4444 0.0 0.013996052395478199 0.2013278306118787 1008.298492732819 421.0 2591.6000000000004 0.9563884582602485 0.9942580297864705\n",
    "\n",
    "5555 0.0 0.011119081779053085 0.09935437589670014 2902.1370157819224 951.5 9373.7 0.8726586253331841 0.6664275466284074\n",
    "5555 0.0 0.014354925533823793 0.19127938273820205 1018.201955858604 422.0 2700.1000000000045 0.9559743631339312 0.9960523954781985\n",
    "\n",
    "6666 0.0 0.007173601147776184 0.0979196556671449 2935.169835007174 955.0 8658.600000000002 0.8726464159210671 0.6664275466284074\n",
    "6666 0.0 0.016149291225551768 0.20473712542616185 1046.2881751300915 432.5 2732.8 0.9547285653201916 0.9940785932172976\n",
    "\n",
    "7777 0.0 0.006456241032998565 0.10222381635581061 2949.4409971305595 969.25 8905.900000000009 0.8716735997218593 0.6553084648493543\n",
    "7777 0.0 0.013816615826305402 0.2086847299479634 1050.7840480890006 437.5 2785.3 0.9545360947490835 0.9946169029248161\n",
    "\n",
    "8888 0.0 0.0068149210903873745 0.10688665710186514 2885.4922883787663 911.75 9153.100000000002 0.8744365730223742 0.6667862266857962\n",
    "8888 0.0 0.012022250134577427 0.19989233805849632 1024.9979364794544 418.5 2673.9000000000005 0.9556383828514529 0.9946169029248161\n",
    "\n",
    "9999 0.0 0.007890961262553802 0.09505021520803443 2947.022238163558 954.0 9308.000000000013 0.8724852059587944 0.6685796269727403\n",
    "9999 0.0 0.013098869549614211 0.20473712542616185 1045.9545128297148 430.5 2767.9 0.9543495848495924 0.993719720078952\n",
    "\n",
    "1010 0.0 0.007173601147776184 0.10186513629842181 2919.2385222381636 911.75 9282.400000000003 0.873687974481546 0.6696556671449068\n",
    "1010 0.0 0.013996052395478199 0.2147855732998385 1026.7513009151264 419.5 2772.4 0.9555555421157754 0.996411268616544\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "box",
   "language": "python",
   "name": "box"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
