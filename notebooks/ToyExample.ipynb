{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ToyExample.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ! pip install wandb"
      ],
      "metadata": {
        "id": "-AmBVSN1efjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApUoYNmKeT_-"
      },
      "outputs": [],
      "source": [
        "\n",
        "import time\n",
        "import torch\n",
        "import math\n",
        "import argparse\n",
        "import os\n",
        "import json\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--no_cuda', action='store_true', default=False, help='disables CUDA training (eg. no nvidia GPU)')\n",
        "parser.add_argument('--epochs', type=int, default=1000, help='number of epochs to train')\n",
        "# model parameters\n",
        "parser.add_argument('--model', type=str, default='softbox', help='model type: choose from softbox, gumbel')\n",
        "parser.add_argument('--box_embedding_dim', type=int, default=40, help='box embedding dimension')\n",
        "parser.add_argument('--softplus_temp', type=float, default=1.0, help='beta of softplus function')\n",
        "# gumbel box parameters\n",
        "parser.add_argument('--gumbel_beta', type=float, default=1.0, help='beta value for gumbel distribution')\n",
        "parser.add_argument('--scale', type=float, default=1.0, help='scale value for gumbel distribution')\n",
        "\n",
        "parser.add_argument('--dataset', type=str, default='GALEN', help='dataset')\n",
        "parser.add_argument('--using_rbox', type=int, default=1, help='using_rbox')\n",
        "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
        "\n",
        "parser.add_argument('--dimension', type=int, default=50, help='dimension')\n",
        "parser.add_argument('--learning_rate', type=int, default=0.001, help='learning_rate')\n",
        "parser.add_argument('--batch_size', type=int, default=256, help='batch_size')\n",
        "parser.add_argument('--seed', type=int, default=1111, help='seed')\n",
        "\n",
        "args = parser.parse_args(args=['--no_cuda'] )\n",
        "args.save_to = \"./checkpoints/\" + args.model\n",
        "\n",
        "gpu = args.gpu\n",
        "dimension = args.dimension\n",
        "learning_rate = args.learning_rate\n",
        "batch_size = args.batch_size\n",
        "seed = args.seed\n",
        "dataset = args.dataset\n",
        "using_rbox = args.using_rbox\n",
        "# device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = 'cpu'\n"
      ],
      "metadata": {
        "id": "lxGEtoeKeXgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import uniform\n",
        "\n",
        "eps = 1e-8\n",
        "\n",
        "def l2_side_regularizer(box, log_scale: bool = True):\n",
        "    \"\"\"Applies l2 regularization on all sides of all boxes and returns the sum.\n",
        "    \"\"\"\n",
        "    min_x = box.min_embed \n",
        "    delta_x = box.delta_embed  \n",
        "\n",
        "    if not log_scale:\n",
        "        return torch.mean(delta_x ** 2)\n",
        "    else:\n",
        "        return torch.mean(F.relu(min_x + delta_x - 1 + eps )) +  torch.mean(F.relu(-min_x - eps)) #+ F.relu(torch.norm(min_x, p=2)-1)\n",
        "\n",
        "class Box:\n",
        "    def __init__(self, min_embed, max_embed):\n",
        "        self.min_embed = min_embed\n",
        "        self.max_embed = max_embed\n",
        "        self.delta_embed = max_embed - min_embed\n",
        "        \n",
        "class BoxEL(nn.Module):\n",
        "    def __init__(self, entity_size, vocab_size, relation_size, embed_dim, min_init_value, delta_init_value, relation_init_value, scaling_init_value, args):\n",
        "        super(BoxEL, self).__init__()\n",
        "        min_embedding = self.init_concept_embedding(vocab_size, embed_dim, min_init_value)\n",
        "        delta_embedding = self.init_concept_embedding(vocab_size, embed_dim, delta_init_value)\n",
        "        relation_embedding = self.init_concept_embedding(relation_size, embed_dim, relation_init_value)\n",
        "        scaling_embedding = self.init_concept_embedding(relation_size, embed_dim, scaling_init_value)\n",
        "#         \n",
        "        self.temperature = args.softplus_temp\n",
        "        self.min_embedding = nn.Parameter(min_embedding)\n",
        "        self.delta_embedding = nn.Parameter(delta_embedding)\n",
        "        self.relation_embedding = nn.Parameter(relation_embedding)\n",
        "        self.scaling_embedding = nn.Parameter(scaling_embedding)\n",
        "        self.min_embedding = nn.Parameter(min_embedding)\n",
        "        self.entity_embedding = nn.Parameter( self.init_concept_embedding(entity_size, embed_dim, min_init_value) )\n",
        "        \n",
        "        self.gumbel_beta = args.gumbel_beta\n",
        "        self.scale = args.scale\n",
        "\n",
        "    def forward(self, data):\n",
        "        # ABox concept assertion\n",
        "        points = self.entity_embedding[train_data[0][:,0]]\n",
        "        nf1_min = self.min_embedding[data[0][:,1:]]\n",
        "        nf1_delta = self.delta_embedding[data[0][:,1:]]\n",
        "        nf1_max = nf1_min+torch.exp(nf1_delta)\n",
        "        boxes = Box(nf1_min[:, 0, :], nf1_max[:, 0, :])\n",
        "        concept_assertion_loss, ca_reg = self.concept_assertion_loss(points, boxes)\n",
        "        # ABox role assertion\n",
        "        points1= self.entity_embedding[train_data[1][:,0]]\n",
        "        points2 = self.entity_embedding[train_data[1][:,2]]\n",
        "        relation = self.relation_embedding[data[1][:,1]]\n",
        "        scaling = self.scaling_embedding[data[1][:,1]]\n",
        "        role_assertion_loss = self.role_assertion_loss(points1, relation, scaling, points2)\n",
        "        \n",
        "        # TBox nf1\n",
        "        nf1_min = self.min_embedding[data[2][:,[0,2]]]\n",
        "        nf1_delta = self.delta_embedding[data[2][:,[0,2]]]\n",
        "        nf1_max = nf1_min+torch.exp(nf1_delta)\n",
        "        boxes1 = Box(nf1_min[:, 0, :], nf1_max[:, 0, :])\n",
        "        boxes2 = Box(nf1_min[:, 1, :], nf1_max[:, 1, :])\n",
        "        nf1_loss, nf1_reg_loss = self.nf1_loss(boxes1, boxes2)\n",
        "         # TBox nf2\n",
        "        nf2_min = self.min_embedding[data[3]]\n",
        "        nf2_delta = self.delta_embedding[data[3]]\n",
        "        nf2_max = nf2_min+torch.exp(nf2_delta)\n",
        "        boxes1 = Box(nf2_min[:, 0, :], nf2_max[:, 0, :])\n",
        "        boxes2 = Box(nf2_min[:, 1, :], nf2_max[:, 1, :])\n",
        "        boxes3 = Box(nf2_min[:, 2, :], nf2_max[:, 2, :])\n",
        "        nf2_loss,nf2_reg_loss = self.nf2_loss(boxes1, boxes2, boxes3)\n",
        "         # TBox nf3\n",
        "        nf3_min = self.min_embedding[data[4][:,[0,2]]]\n",
        "        nf3_delta = self.delta_embedding[data[4][:,[0,2]]]\n",
        "        nf3_max = nf3_min+torch.exp(nf3_delta)\n",
        "        relation = self.relation_embedding[data[4][:,1]]\n",
        "        scaling = self.scaling_embedding[data[4][:,1]]\n",
        "        boxes1 = Box(nf3_min[:, 0, :], nf3_max[:, 0, :])\n",
        "        boxes2 = Box(nf3_min[:, 1, :], nf3_max[:, 1, :])\n",
        "        nf3_loss,nf3_reg_loss = self.nf3_loss(boxes1, relation, scaling, boxes2)\n",
        "         # TBox nf4\n",
        "        nf4_min = self.min_embedding[data[5][:,1:]]\n",
        "        nf4_delta = self.delta_embedding[data[5][:,1:]]\n",
        "        nf4_max = nf4_min+torch.exp(nf4_delta)\n",
        "        relation = self.relation_embedding[data[5][:,0]]\n",
        "        scaling = self.scaling_embedding[data[5][:,0]]\n",
        "        boxes1 = Box(nf4_min[:, 0, :], nf4_max[:, 0, :])\n",
        "        boxes2 = Box(nf4_min[:, 1, :], nf4_max[:, 1, :])\n",
        "        nf4_loss,nf4_reg_loss = self.nf4_loss(relation, scaling, boxes1, boxes2)\n",
        "         # TBox disjoint\n",
        "        disjoint_min = self.min_embedding[data[6]]\n",
        "        disjoint_delta = self.delta_embedding[data[6]]\n",
        "        disjoint_max = disjoint_min+torch.exp(disjoint_delta)\n",
        "        boxes1 = Box(disjoint_min[:, 0, :], disjoint_max[:, 0, :])\n",
        "        boxes2 = Box(disjoint_min[:, 1, :], disjoint_max[:, 1, :])\n",
        "        disjoint_loss,disjoint_reg_loss = self.disjoint_loss(boxes1, boxes2)\n",
        "        # TBox nf1_neg\n",
        "        nf1_neg_min = self.min_embedding[data[7][:,[0,2]]]\n",
        "        nf1_neg_delta = self.delta_embedding[data[7][:,[0,2]]]\n",
        "        nf1_neg_max = nf1_neg_min+torch.exp(nf1_neg_delta)\n",
        "        boxes1 = Box(nf1_neg_min[:, 0, :], nf1_neg_max[:, 0, :])\n",
        "        boxes2 = Box(nf1_neg_min[:, 1, :], nf1_neg_max[:, 1, :])\n",
        "        nf1_neg_loss, nf1_neg_reg_loss = self.nf1_loss(boxes1, boxes2)\n",
        "        nf1_neg_loss = 1 - nf1_neg_loss\n",
        "\n",
        "        return concept_assertion_loss.sum(), role_assertion_loss.sum(), nf1_loss.sum(), nf1_neg_loss.sum(), nf2_loss.sum(), nf3_loss.sum(), nf4_loss.sum(), disjoint_loss.sum(), nf1_reg_loss, nf1_neg_reg_loss, nf2_reg_loss , nf3_reg_loss , nf4_reg_loss, disjoint_reg_loss\n",
        "\n",
        "    def concept_assertion_loss(self, points, boxes):\n",
        "        concept_assertion_loss = torch.norm(F.relu(points - boxes.max_embed + eps), p=2, dim=1,keepdim=True) + torch.norm(F.relu( boxes.min_embed  - points -eps), p=2, dim=1,keepdim=True)\n",
        "        return concept_assertion_loss, l2_side_regularizer(boxes, log_scale=True) \n",
        "\n",
        "    def role_assertion_loss(self, points1, relation, scaling, points2):\n",
        "        trans_point = points1*scaling+relation\n",
        "        role_assertion_loss = torch.norm(trans_point-points2,p=2, dim=1,keepdim=True)\n",
        "        return role_assertion_loss\n",
        "\n",
        "    def get_cond_probs(self, data):\n",
        "        nf3_min = self.min_embedding[data[:,[0,2]]]\n",
        "        nf3_delta = self.delta_embedding[data[:,[0,2]]]\n",
        "        nf3_max = nf3_min+torch.exp(nf3_delta)\n",
        "        relation = self.relation_embedding[data[:,1]]\n",
        "        boxes1 = Box(nf3_min[:, 0, :], nf3_max[:, 0, :])\n",
        "        boxes2 = Box(nf3_min[:, 1, :], nf3_max[:, 1, :])\n",
        "        log_intersection = torch.log(torch.clamp(self.volumes(self.intersection(boxes1, boxes2)), 1e-10, 1e4))\n",
        "        log_box2 = torch.log(torch.clamp(self.volumes(boxes2), 1e-10, 1e4))\n",
        "        return torch.exp(log_intersection-log_box2)\n",
        "\n",
        "    def volumes(self, boxes):\n",
        "        return F.softplus(boxes.delta_embed, beta=self.temperature).prod(1)\n",
        "\n",
        "    def intersection(self, boxes1, boxes2):\n",
        "        intersections_min = torch.max(boxes1.min_embed, boxes2.min_embed)\n",
        "        intersections_max = torch.min(boxes1.max_embed, boxes2.max_embed)\n",
        "        intersection_box = Box(intersections_min, intersections_max)\n",
        "        return intersection_box\n",
        "    \n",
        "    def inclusion_loss(self, boxes1, boxes2):\n",
        "        log_intersection = torch.log(torch.clamp(self.volumes(self.intersection(boxes1, boxes2)), 1e-10, 1e4))\n",
        "        log_box1 = torch.log(torch.clamp(self.volumes(boxes1), 1e-10, 1e4))\n",
        "        return 1-torch.exp(log_intersection-log_box1)\n",
        "    \n",
        "    def nf1_loss(self, boxes1, boxes2):\n",
        "        return self.inclusion_loss(boxes1, boxes2), l2_side_regularizer(boxes1, log_scale=True) + l2_side_regularizer(boxes2, log_scale=True)\n",
        "        \n",
        "    def nf2_loss(self, boxes1, boxes2, boxes3):\n",
        "        inter_box = self.intersection(boxes1, boxes2)\n",
        "        return self.inclusion_loss(inter_box, boxes3), l2_side_regularizer(inter_box, log_scale=True) + l2_side_regularizer(boxes1, log_scale=True) + l2_side_regularizer(boxes2, log_scale=True) + l2_side_regularizer(boxes3, log_scale=True)\n",
        "    \n",
        "    def nf3_loss(self, boxes1, relation, scaling, boxes2):\n",
        "        trans_min = boxes1.min_embed*(scaling + eps) + relation\n",
        "        trans_max = boxes1.max_embed*(scaling + eps) + relation\n",
        "        trans_boxes = Box(trans_min, trans_max)\n",
        "        return self.inclusion_loss(trans_boxes, boxes2), l2_side_regularizer(trans_boxes, log_scale=True) + l2_side_regularizer(boxes1, log_scale=True) + l2_side_regularizer(boxes2, log_scale=True) \n",
        "    \n",
        "    def nf4_loss(self, relation, scaling, boxes1, boxes2):\n",
        "        trans_min = (boxes1.min_embed - relation)/(scaling + eps)\n",
        "        trans_max = (boxes1.max_embed - relation)/(scaling + eps)\n",
        "        trans_boxes = Box(trans_min, trans_max)\n",
        "        return self.inclusion_loss(trans_boxes, boxes2), l2_side_regularizer(trans_boxes, log_scale=True) + l2_side_regularizer(boxes1, log_scale=True) + l2_side_regularizer(boxes2, log_scale=True) \n",
        "        \n",
        "    def disjoint_loss(self, boxes1, boxes2):\n",
        "        log_intersection = torch.log(torch.clamp(self.volumes(self.intersection(boxes1, boxes2)), 1e-10, 1e4))\n",
        "        log_boxes1 = torch.log(torch.clamp(self.volumes(boxes1), 1e-10, 1e4))\n",
        "        log_boxes2 = torch.log(torch.clamp(self.volumes(boxes2), 1e-10, 1e4))\n",
        "        union = log_boxes1 + log_boxes2\n",
        "        return torch.exp(log_intersection-union), l2_side_regularizer(boxes1, log_scale=True) + l2_side_regularizer(boxes2, log_scale=True)\n",
        "        \n",
        "    def role_inclusion_loss(self, translation_1,translation_2,scaling_1,scaling_2):\n",
        "        loss_1 = torch.norm(translation_1-translation_2, p=2, dim=1,keepdim=True)\n",
        "        loss_2 = torch.norm(F.relu(scaling_1/(scaling_2 +eps) -1), p=2, dim=1,keepdim=True)\n",
        "        return loss_1+loss_2\n",
        "    \n",
        "    def role_chain_loss(self, translation_1,translation_2,translation_3,scaling_1,scaling_2,scaling_3):\n",
        "        loss_1 = torch.norm(scaling_1*translation_1 + translation_2 -translation_3, p=2, dim=1,keepdim=True)\n",
        "        loss_2 = torch.norm(F.relu(scaling_1*scaling_2/(scaling_3 +eps) -1), p=2, dim=1,keepdim=True)\n",
        "        return loss_1+loss_2\n",
        "    \n",
        "    def init_concept_embedding(self, vocab_size, embed_dim, init_value):\n",
        "        distribution = uniform.Uniform(init_value[0], init_value[1])\n",
        "        box_embed = distribution.sample((vocab_size, embed_dim))\n",
        "        return box_embed\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oqeQJNvJeZld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "train_data = []\n",
        "# ABox\n",
        "train_data.append(torch.Tensor([[0,4],[1,4],[2,5],[3,5]]).long().to(device)) # concept assertion\n",
        "train_data.append(torch.Tensor([[0,1,2],[3,2,1]]).long().to(device)) # role assertion\n",
        "# Tbox\n",
        "train_data.append(torch.Tensor([[1,0,0],[2,0,0],[3,0,0],[4,0,1],[4,0,2],[5,0,2],[5,0,3]]).long().to(device)) #nf1 c in d\n",
        "train_data.append(torch.Tensor([[1,2,4],[2,3,5]]).long().to(device)) # nf2\n",
        "train_data.append(torch.Tensor([[2,0,0]]).long().to(device)) # nf3\n",
        "train_data.append(torch.Tensor([[0,0,2]]).long().to(device)) #nf4\n",
        "train_data.append(torch.Tensor([[1,3,0]]).long().to(device)) #disjoint\n",
        "train_data.append(torch.Tensor([[2,0,5],[3,0,5],[1,0,4],[2,0,4]]).long().to(device)) # nf1 neg\n",
        "train_data.append(torch.Tensor([[6]]).long().to(device)) #disjoint\n",
        "\n",
        "#RBox\n",
        "train_data.append(torch.Tensor([[1,0],[2,0]]).long().to(device)) \n",
        "train_data.append(torch.Tensor([[1,2,3],[1,2,3]]).long().to(device)) \n",
        "\n",
        "train_data\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hnkd7-ee_yE",
        "outputId": "71b99266-88b2-4e99-abb9-742bb6d991b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[0, 4],\n",
              "         [1, 4],\n",
              "         [2, 5],\n",
              "         [3, 5]]), tensor([[0, 1, 2],\n",
              "         [3, 2, 1]]), tensor([[1, 0, 0],\n",
              "         [2, 0, 0],\n",
              "         [3, 0, 0],\n",
              "         [4, 0, 1],\n",
              "         [4, 0, 2],\n",
              "         [5, 0, 2],\n",
              "         [5, 0, 3]]), tensor([[1, 2, 4],\n",
              "         [2, 3, 5]]), tensor([[2, 0, 0]]), tensor([[0, 0, 2]]), tensor([[1, 3, 0]]), tensor([[2, 0, 5],\n",
              "         [3, 0, 5],\n",
              "         [1, 0, 4],\n",
              "         [2, 0, 4]]), tensor([[6]]), tensor([[1, 0],\n",
              "         [2, 0]]), tensor([[1, 2, 3],\n",
              "         [1, 2, 3]])]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"basic_box\",  reinit=False, config=args)\n",
        "# "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "sctyyPc3fOPY",
        "outputId": "82e6ef74-b14a-4c16-a7f0-e25267b75d60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.18"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220618_154503-16lgnxf3</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/boxiong/basic_box/runs/16lgnxf3\" target=\"_blank\">denim-morning-208</a></strong> to <a href=\"https://wandb.ai/boxiong/basic_box\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/boxiong/basic_box/runs/16lgnxf3?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f6946f4af90>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(888)\n",
        "model = BoxEL(4, 6, 7, 2, [1e-4,0.2], [-0.1, 0], [-0.1,0.1], [0.9, 1.1], args).to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybzyBx7KfRDN",
        "outputId": "9c8eff04-bd75-4693-e802-723d4b3b6ef2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BoxEL()"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def plot_box(boxes, relation, scaling_emb, epoch, loss):\n",
        "    clear_output(wait=True)\n",
        "    plt.figure(figsize=(5,4))\n",
        "\n",
        "#     plt.subplot(121)\n",
        "    \n",
        "    labels = ['Person','Male','Parent','Female','Father','Mother']\n",
        "    color = ['r','b','g','purple','m','c']\n",
        "    \n",
        "    # Plot individual embedding\n",
        "    x = model.entity_embedding.cpu().detach().numpy()[:,0]\n",
        "    y = model.entity_embedding.cpu().detach().numpy()[:,1]\n",
        "    label = ['Alex','Bob','Alice','Maria']\n",
        "    plt.scatter(x,y,c=['r','m','lightgreen','darkblue'])\n",
        "    for i, txt in enumerate(label):\n",
        "        plt.annotate(txt, (x[i], y[i]))\n",
        "\n",
        "    # Plot concept embedding\n",
        "    for i in range(boxes.min_embed.shape[0]):\n",
        "        x1,x2,w,h = boxes.min_embed[i][0].detach().numpy(),boxes.min_embed[i][1].detach().numpy(),boxes.max_embed[i][0].detach().numpy()-boxes.min_embed[i][0].detach().numpy(), boxes.max_embed[i][1].detach().numpy()-boxes.min_embed[i][1].detach().numpy()\n",
        "        rect=mpatches.Rectangle((x1,x2),w,h, fill = False, color = color[i],linewidth = 2, alpha=0.6, facecolor=color[i])\n",
        "        plt.gca().add_patch(rect)\n",
        "        plt.text(x1+w-0.14,x2+h-0.05, labels[i], color = color[i])\n",
        "        \n",
        "    plt.xlim(-0.03,1.03)\n",
        "    plt.ylim(-0.03,1.03)\n",
        "    plt.savefig('toy_example.pdf', dpi=1200)\n",
        "    \n",
        "#     plt.title(\"Classes embedding\")\n",
        "#     x1,x2,w,h = boxes.min_embed[2][0],boxes.min_embed[2][1],boxes.max_embed[2][0]-boxes.min_embed[2][0], boxes.max_embed[2][1]-boxes.min_embed[2][1]\n",
        "#     plt.arrow(x1.cpu().detach().numpy(), x2.cpu().detach().numpy(), rel_emb[0][0].cpu().detach().numpy(), rel_emb[0][1].cpu().detach().numpy(), head_width=0.01, head_length=0.01, fc='k', ec='k')\n",
        "#     plt.text(x1 + rel_emb[0][0]/2, x2+rel_emb[0][1]/2, 'hasChild', color = 'black')\n",
        "    \n",
        "    \n",
        "#     plt.subplot(122)\n",
        "    \n",
        "#     labels = ['Person','Male','Parent','Femal','Father','Mother']\n",
        "#     color = ['r','b','g','purple','m','c']\n",
        "    \n",
        "#     # Plot individual embedding\n",
        "#     x = model.entity_embedding.cpu().detach().numpy()[:,0]\n",
        "#     y = model.entity_embedding.cpu().detach().numpy()[:,1]\n",
        "#     label = ['Alex','Bob','Alice','Maria']\n",
        "#     plt.scatter(x,y,c=['r','m','lightgreen','darkblue'])\n",
        "#     for i, txt in enumerate(label):\n",
        "#         plt.annotate(txt, (x[i], y[i]))\n",
        "        \n",
        "#     plt.arrow(x, y, rel_emb[0][0].cpu().detach().numpy(), rel_emb[0][1].cpu().detach().numpy(), head_width=0.01, head_length=0.01, fc='k', ec='k')\n",
        "#     plt.text(x1 + rel_emb[0][0]/2, x2+rel_emb[0][1]/2, 'hasChild', color = 'black')\n",
        "    \n",
        "    \n",
        "#     x1,x2,w,h = boxes.min_embed[2][0],boxes.min_embed[2][1],boxes.max_embed[2][0]-boxes.min_embed[2][0], boxes.max_embed[2][1]-boxes.min_embed[2][1]\n",
        "#     rect=mpatches.Rectangle((x1,x2),w,h, fill = False, color = 'green', linewidth = 1, alpha=0.6)\n",
        "#     plt.gca().add_patch(rect)\n",
        "#     plt.text(x1, x2+0.9*h, 'Parent', color = 'green')\n",
        "\n",
        "#     trans_min = boxes.min_embed[2:3] + rel_emb[0]\n",
        "#     trans_max = trans_min + (boxes.max_embed[2:3] - boxes.min_embed[2:3])*scaling_emb[0]\n",
        "    \n",
        "    \n",
        "#     x1,x2,w,h = trans_min[0][0],trans_min[0][1],trans_max[0][0]-trans_min[0][0], trans_max[0][1]-trans_min[0][1]\n",
        "#     rect=mpatches.Rectangle((x1,x2),w,h, fill = False, color = 'orange', linewidth = 1, alpha=0.6)\n",
        "#     plt.gca().add_patch(rect)\n",
        "#     plt.text(x1, x2+0.9*h, 'Parent + hasChild ', color = 'orange')\n",
        "    \n",
        "#     x1,x2,w,h = boxes.min_embed[0][0],boxes.min_embed[0][1],boxes.max_embed[0][0]-boxes.min_embed[0][0], boxes.max_embed[0][1]-boxes.min_embed[0][1]\n",
        "#     rect=mpatches.Rectangle((x1,x2),w,h, fill = False, color = 'red', linewidth = 1, alpha=0.6)\n",
        "#     plt.gca().add_patch(rect)\n",
        "#     plt.text(x1, x2+0.9*h, 'Person', color = 'red')\n",
        "    \n",
        "#     plt.xlim(-0.5,1)\n",
        "#     plt.ylim(-0.5,1)\n",
        "#     plt.title(\"Relation embedding\")\n",
        "\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "mx1h_fMNfWWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.train()\n",
        "for epoch in range(400):\n",
        "#     concept_assertion_loss, role_assertion_loss, nf1_loss, nf2_loss, nf3_loss, nf4_loss, disjoint_loss, nf3_neg_loss, role_inclusion_loss, role_chain_loss, concept_inclusion_reg_loss,nf1_reg_loss, nf2_reg_loss , nf3_reg_loss , nf4_reg_loss , disjoint_reg_loss , nf3_neg_reg_loss = \n",
        "    print(epoch)\n",
        "    concept_assertion_loss, role_assertion_loss, nf1_loss, nf1_neg_loss, nf2_loss, nf3_loss, nf4_loss, disjoint_loss, nf1_reg_loss, nf1_neg_reg_loss, nf2_reg_loss , nf3_reg_loss , nf4_reg_loss, disjoint_reg_loss = model(train_data)\n",
        "    loss =  concept_assertion_loss + role_assertion_loss + nf1_loss + nf1_reg_loss + nf2_loss + nf2_reg_loss + disjoint_loss + disjoint_reg_loss + nf3_loss + nf3_reg_loss + nf4_loss + nf4_reg_loss\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if epoch % 399 ==0:\n",
        "        min_emb, delta_emb, max_emb, rel_emb, scaling_emb = model.min_embedding, model.delta_embedding, model.min_embedding +torch.exp(model.delta_embedding), model.relation_embedding, model.scaling_embedding\n",
        "        boxes = Box(min_emb, max_emb)\n",
        "        plot_box(boxes, rel_emb.detach().numpy(), scaling_emb.detach().numpy(), epoch, loss.item())\n",
        "#     if epoch % 10 == 0:\n",
        "#         print(nf1_loss.item(), nf2_loss.item(), nf3_loss.item(), nf4_loss.item(), disjoint_loss.item(), nf3_neg_loss.item(), nf1_reg_loss.item(),nf3_reg_loss.item(), nf4_reg_loss.item() )   \n",
        "        \n",
        "        \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMc3HIqSfYma",
        "outputId": "0852c978-e779-4f69-9a3a-f5920c5df9cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: Setting the 'color' property will override the edgecolor or facecolor properties.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bkGeF0Mgfbj6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}